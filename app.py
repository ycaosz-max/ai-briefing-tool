# AIç®€æŠ¥å°åŠ©æ‰‹ - è¯­éŸ³ç‰ˆv2.1.0 (Cloud Ready)
# éƒ¨ç½²åˆ° Streamlit Cloud çš„ç‰ˆæœ¬

import streamlit as st
from openai import OpenAI
import os
import tempfile
import io

# ========== é¡µé¢è®¾ç½® ==========
st.set_page_config(page_title="AIè¯­éŸ³ç®€æŠ¥åŠ©æ‰‹", page_icon="ğŸ™ï¸")

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
.big-title { font-size: 42px; font-weight: bold; color: #FF6B6B; text-align: center; }
.subtitle { font-size: 18px; color: #666; text-align: center; margin-bottom: 30px; }
.voice-box { background-color: #f0f2f6; padding: 20px; border-radius: 15px; border-left: 5px solid #FF6B6B; margin: 10px 0; }
.stButton>button { border-radius: 20px; height: 3em; font-weight: bold; width: 100%; }
</style>
""", unsafe_allow_html=True)

# ========== æ ‡é¢˜ ==========
st.markdown('<p class="big-title">ğŸ™ï¸ AIè¯­éŸ³ç®€æŠ¥åŠ©æ‰‹</p>', unsafe_allow_html=True)
st.markdown('<p class="subtitle">è¯­éŸ³ç›´æ¥è½¬æ–‡å­—ï¼Œè‡ªåŠ¨ç”Ÿæˆç®€æŠ¥</p>', unsafe_allow_html=True)

# ========== ä¾§è¾¹æ è®¾ç½® ==========
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    
    # å…³é”®ä¿®æ”¹ï¼šä»ç¯å¢ƒå˜é‡æˆ–secretsè¯»å–APIå¯†é’¥ï¼ˆCloudå®‰å…¨è¦æ±‚ï¼‰
    api_key = st.text_input("ğŸ”‘ ç¡…åŸºæµåŠ¨ APIå¯†é’¥", 
                           value=st.secrets.get("SILICONFLOW_API_KEY", ""),
                           type="password",
                           help="åœ¨ siliconflow.cn å…è´¹è·å–")
    
    if not api_key:
        st.warning("âš ï¸ è¯·å…ˆè¾“å…¥APIå¯†é’¥")
        st.markdown("""
        **è·å–æ­¥éª¤ï¼š**
        1. è®¿é—® [siliconflow.cn](https://siliconflow.cn)
        2. æ‰‹æœºå·æ³¨å†Œï¼ˆé€14å…ƒï¼‰
        3. åˆ›å»ºAPIå¯†é’¥
        4. å¤åˆ¶åˆ°å·¦ä¾§è¾“å…¥æ¡†
        """)
    else:
        st.success("âœ… å¯†é’¥å·²é…ç½®")

# ========== è¯­éŸ³è½¬æ–‡å­—å‡½æ•° ==========
def transcribe_audio(audio_bytes, api_key):
    """ä½¿ç”¨ç¡…åŸºæµåŠ¨Whisper APIè½¬æ–‡å­—"""
    try:
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.siliconflow.cn/v1"
        )
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_path = tmp_file.name
        
        with open(tmp_path, "rb") as audio:
            transcription = client.audio.transcriptions.create(
                model="FunAudioLLM/SenseVoiceSmall",
                file=audio,
                response_format="text"
            )
        
        os.unlink(tmp_path)
        return {"success": True, "text": transcription}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

# ========== ä¸»ç•Œé¢ ==========
if not api_key:
    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§è¾¹æ è¾“å…¥APIå¯†é’¥")
else:
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ¤ è¯­éŸ³è¾“å…¥")
        
        # æ–¹å¼ä¸€ï¼šå®æ—¶å½•éŸ³
        st.markdown("""
        <div class="voice-box">
            <h4>æ–¹å¼ä¸€ï¼šå®æ—¶å½•éŸ³è½¬æ–‡å­—</h4>
            <p style="color: #666; font-size: 14px;">ç‚¹å‡»å½•éŸ³ï¼Œè¯´å®Œåè‡ªåŠ¨è½¬å†™å¹¶å¡«å…¥å³ä¾§</p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            from streamlit_mic_recorder import mic_recorder
            
            audio = mic_recorder(
                start_prompt="ğŸ™ï¸ ç‚¹å‡»å¼€å§‹å½•éŸ³",
                stop_prompt="â¹ï¸ ç‚¹å‡»åœæ­¢å¹¶è½¬å†™",
                just_once=True,
                key="mic_recorder"
            )
            
            if audio and audio["bytes"]:
                with st.spinner("ğŸ¤– AIæ­£åœ¨è½¬å†™..."):
                    result = transcribe_audio(audio["bytes"], api_key)
                    
                    if result["success"]:
                        st.session_state.transcribed_text = result["text"]
                        st.success(f"âœ… è½¬å†™å®Œæˆï¼å…± {len(result['text'])} å­—")
                        st.rerun()
                    else:
                        st.error(f"âŒ è½¬å†™å¤±è´¥ï¼š{result['error']}")
                        
        except ImportError:
            st.warning("âš ï¸ å½•éŸ³ç»„ä»¶åŠ è½½ä¸­...")
            st.info("å¦‚æœé•¿æ—¶é—´æ— æ³•åŠ è½½ï¼Œè¯·åˆ·æ–°é¡µé¢")
        
        st.divider()
        
        # æ–¹å¼äºŒï¼šä¸Šä¼ å½•éŸ³æ–‡ä»¶
        st.subheader("ğŸ“ æ–¹å¼äºŒï¼šä¸Šä¼ å½•éŸ³ï¼ˆè‡ªåŠ¨è½¬æ–‡å­—ï¼‰")
        
        audio_file = st.file_uploader(
            "ä¸Šä¼ å½•éŸ³æ–‡ä»¶ï¼ˆmp3/wav/m4aï¼‰", 
            type=['mp3', 'wav', 'm4a', 'webm'],
            help="ä¸Šä¼ åè‡ªåŠ¨è½¬ä¸ºæ–‡å­—ï¼Œæ— éœ€æ‰‹åŠ¨è¾“å…¥"
        )
        
        if audio_file:
            st.audio(audio_file, format=f'audio/{audio_file.type.split("/")[1]}')
            
            if st.button("ğŸ¯ å¼€å§‹è¯­éŸ³è½¬æ–‡å­—", type="primary", key="transcribe"):
                with st.spinner("ğŸ¤– AIæ­£åœ¨è¯†åˆ«è¯­éŸ³ï¼Œè¯·ç¨å€™..."):
                    result = transcribe_audio(audio_file.getvalue(), api_key)
                    
                    if result["success"]:
                        st.session_state.transcribed_text = result["text"]
                        st.success(f"âœ… è¯†åˆ«å®Œæˆï¼å…± {len(result['text'])} ä¸ªå­—ç¬¦")
                        st.markdown("**è¯†åˆ«ç»“æœé¢„è§ˆï¼š**")
                        st.info(result["text"][:200] + "..." if len(result["text"]) > 200 else result["text"])
                        st.rerun()
                    else:
                        st.error(f"âŒ è¯†åˆ«å¤±è´¥ï¼š{result['error']}")
                        st.info("æç¤ºï¼šè¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
    
    with col2:
        st.subheader("ğŸ“ ç¼–è¾‘ä¸ç”Ÿæˆ")
        
        briefing_type = st.selectbox(
            "é€‰æ‹©ç®€æŠ¥ç±»å‹",
            ["å·¥ä½œæ—¥æŠ¥", "ä¼šè®®çºªè¦", "å­¦ä¹ ç¬”è®°", "æ–°é—»æ‘˜è¦"],
            key="briefing_type"
        )
        
        default_text = st.session_state.get("transcribed_text", "")
        
        content = st.text_area(
            "ç¼–è¾‘å†…å®¹ï¼ˆå¯ä¿®æ”¹AIè¯†åˆ«çš„æ–‡å­—ï¼‰",
            value=default_text,
            height=300,
            placeholder="åœ¨è¿™é‡Œç¼–è¾‘...å¯ä»¥æ‰‹åŠ¨è¾“å…¥ã€ç²˜è´´ï¼Œæˆ–ä»å·¦ä¾§è¯­éŸ³å¯¼å…¥"
        )
        
        if content != st.session_state.get("transcribed_text", ""):
            st.session_state.transcribed_text = content
        
        custom_req = st.text_input("ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šé‡ç‚¹çªå‡ºæ•°æ®ï¼Œç”¨è¡¨æ ¼å±•ç¤º")
        
        col_gen, col_clear = st.columns([3, 1])
        with col_gen:
            if st.button("âœ¨ ç”Ÿæˆç®€æŠ¥", type="primary", use_container_width=True):
                if not content.strip():
                    st.error("âŒ å†…å®¹ä¸èƒ½ä¸ºç©ºï¼è¯·å…ˆè¯­éŸ³è¾“å…¥æˆ–æ‰‹åŠ¨å¡«å†™")
                else:
                    with st.spinner("ğŸ¤– AIæ­£åœ¨æ•´ç†æˆç®€æŠ¥..."):
                        try:
                            client = OpenAI(
                                api_key=api_key,
                                base_url="https://api.siliconflow.cn/v1"
                            )
                            
                            prompts = {
                                "å·¥ä½œæ—¥æŠ¥": "å°†ä»¥ä¸‹å†…å®¹æ•´ç†æˆå·¥ä½œæ—¥æŠ¥ï¼ŒåŒ…å«ï¼š1ä»Šå¤©å®Œæˆçš„å·¥ä½œ 2é‡åˆ°çš„é—®é¢˜ 3æ˜å¤©çš„è®¡åˆ’",
                                "ä¼šè®®çºªè¦": "å°†ä»¥ä¸‹å†…å®¹æ•´ç†æˆä¼šè®®çºªè¦ï¼ŒåŒ…å«ï¼š1ä¼šè®®ä¸»é¢˜ 2è®¨è®ºè¦ç‚¹ 3å†³è®®äº‹é¡¹ 4å¾…åŠä»»åŠ¡",
                                "å­¦ä¹ ç¬”è®°": "å°†ä»¥ä¸‹å†…å®¹æ•´ç†æˆç»“æ„åŒ–å­¦ä¹ ç¬”è®°ï¼ŒåŒ…å«ï¼š1æ ¸å¿ƒæ¦‚å¿µ 2é‡ç‚¹å†…å®¹ 3ä¸ªäººæ€è€ƒ",
                                "æ–°é—»æ‘˜è¦": "å°†ä»¥ä¸‹å†…å®¹æ•´ç†æˆæ–°é—»æ‘˜è¦ï¼ŒåŒ…å«ï¼š1æ ¸å¿ƒäº‹ä»¶ 2å…³é”®æ•°æ® 3å½±å“åˆ†æ"
                            }
                            
                            system_prompt = prompts[briefing_type]
                            if custom_req:
                                system_prompt += f"ã€‚é¢å¤–è¦æ±‚ï¼š{custom_req}"
                            
                            response = client.chat.completions.create(
                                model="deepseek-ai/DeepSeek-V3",
                                messages=[
                                    {"role": "system", "content": system_prompt},
                                    {"role": "user", "content": content}
                                ],
                                temperature=0.7,
                                max_tokens=2000
                            )
                            
                            result = response.choices[0].message.content
                            st.session_state.generated_result = result
                            
                        except Exception as e:
                            st.error(f"âŒ ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        
        with col_clear:
            if st.button("ğŸ—‘ï¸ æ¸…ç©º", use_container_width=True):
                st.session_state.transcribed_text = ""
                if "generated_result" in st.session_state:
                    del st.session_state.generated_result
                st.rerun()
        
        if "generated_result" in st.session_state:
            st.divider()
            st.success("âœ… ç®€æŠ¥ç”Ÿæˆå®Œæˆï¼")
            st.markdown(st.session_state.generated_result)
            st.download_button(
                "ğŸ“‹ ä¸‹è½½ç®€æŠ¥",
                st.session_state.generated_result,
                file_name=f"ç®€æŠ¥_{briefing_type}_{os.path.basename(tempfile.mktemp())[:6]}.txt",
                mime="text/plain"
            )

st.divider()
st.caption("Made with â¤ï¸ | è¯­éŸ³ç‰ˆv2.1.0 - Cloud Ready")